# ğŸš€ DÃ©ployer un ModÃ¨le de Machine Learning en tant que Fonction AWS Lambda

Ce dÃ©pÃ´t contient le code et l'infrastructure pour dÃ©ployer un modÃ¨le de machine learning (modÃ¨le de notation d'essai basÃ© sur BERT) en tant que fonction AWS Lambda serverless, en utilisant AWS CDK (Cloud Development Kit) avec TypeScript.

---

## ğŸ“Œ Vue d'ensemble de l'Architecture

Le workflow de dÃ©ploiement se compose de deux parties principales :

- **Pipeline de Build Docker** : PrÃ©pare le modÃ¨le ML et ses dÃ©pendances pour le dÃ©ploiement  
- **DÃ©ploiement avec AWS CDK** : Provisionne et configure les ressources AWS  

![Architecture](./docs/deployment_workflow.png)

---

## âœ… PrÃ©requis

- Node.js (v18.x ou supÃ©rieur)  
- AWS CLI configurÃ© avec les identifiants appropriÃ©s  
- AWS CDK installÃ© (`npm install -g aws-cdk`)  
- Docker installÃ© et en cours d'exÃ©cution  
- Python 3.11 installÃ© (pour les tests locaux)  

---

## ğŸ—‚ï¸ Structure du Projet

```bash
â”œâ”€â”€ bin/                   # Point d'entrÃ©e de l'application CDK
â”œâ”€â”€ lib/                   # DÃ©finition de la stack CDK
â”œâ”€â”€ image/                 # Fichiers de l'image Docker
â”‚   â”œâ”€â”€ Dockerfile         # Dockerfile multi-Ã©tapes pour le dÃ©ploiement Lambda
â”‚   â”œâ”€â”€ requirements.txt   # DÃ©pendances Python
â”‚   â””â”€â”€ src/               # Code source Python
â”‚       â””â”€â”€ main.py        # Fonction handler Lambda
â”œâ”€â”€ test/                  # Fichiers de test pour la stack CDK
â”œâ”€â”€ cdk.json               # Configuration CDK
â”œâ”€â”€ tsconfig.json          # Configuration TypeScript
â”œâ”€â”€ package.json           # DÃ©pendances Node.js
â””â”€â”€ README.md              # Ce fichier
```

---

## ğŸ³ Pipeline de Build Docker du ModÃ¨le ML

La pipeline de build Docker prÃ©pare votre modÃ¨le ML pour le dÃ©ploiement :

1. **Jeu de donnÃ©es** : DonnÃ©es brutes utilisÃ©es pour l'entraÃ®nement du modÃ¨le  
2. **Traitement des donnÃ©es** : Nettoie et prÃ©pare les donnÃ©es  
3. **EntraÃ®nement du modÃ¨le** : EntraÃ®ne le modÃ¨le de notation d'essai basÃ© sur BERT  
4. **Export final du modÃ¨le** : Exporte le modÃ¨le au format `.h5`  
5. **Image Docker** : Emballe le modÃ¨le avec ses dÃ©pendances  

Le Dockerfile utilise un **processus de build multi-Ã©tapes** afin d'optimiser la taille de l'image :

- **Ã‰tape 1** : Compile les dÃ©pendances et tÃ©lÃ©charge les donnÃ©es NLTK  
- **Ã‰tape 2** : CrÃ©e une image d'exÃ©cution minimale ne contenant que les composants nÃ©cessaires  

---

## â˜ï¸ Processus de DÃ©ploiement avec AWS CDK

### ğŸ”§ Initialisation CDK  
CrÃ©e les ressources AWS nÃ©cessaires pour le dÃ©ploiement via CDK :

- Bucket S3 pour les assets  
- RÃ´les IAM pour le dÃ©ploiement  

### ğŸ“¦ DÃ©finition des Ressources  
Configure la fonction Lambda :

- **Allocation mÃ©moire** : 3008 MB  
- **Timeout** : 180 secondes  
- **Architecture** : `x86_64`  
- **Stockage Ã©phÃ©mÃ¨re** : 10 GB  

### ğŸš€ DÃ©ploiement CDK  

- TÃ©lÃ©charge l'image Docker sur **AWS ECR**  
- CrÃ©e la fonction Lambda  
- Configure l'URL de la fonction avec les rÃ©glages **CORS**  

---

## âš™ï¸ Installation et DÃ©ploiement

### 1. Installer les dÃ©pendances

```bash
npm install
```

### 2. PrÃ©parer votre modÃ¨le ML

Assurez-vous que vos modÃ¨les sont placÃ©s dans les rÃ©pertoires appropriÃ©s :

```
image/models/bert-tokenizer/
image/models/bert-model/
```

Le modÃ¨le TensorFlow doit Ãªtre placÃ© Ã  :

```bash
/var/task/aes_model.h5
```

### 3. Initialiser CDK (premiÃ¨re utilisation)

```bash
npx cdk bootstrap
```

### 4. DÃ©ployer la stack

```bash
npx cdk deploy
```

AprÃ¨s le dÃ©ploiement, l'URL de la fonction Lambda s'affichera dans la sortie.

---

## ğŸ§ª Tester la Fonction DÃ©ployÃ©e

```bash
curl -X POST   -H "Content-Type: application/json"   -d '{"text": "Ceci est un essai pour Ãªtre notÃ©."}'   <FUNCTION_URL>
```

### âœ… RÃ©ponse Exemple

```json
{
  "statusCode": 200,
  "body": {
    "essay score": 4
  }
}
```

---

## ğŸ” DÃ©tails de la Fonction Lambda

La fonction Lambda exÃ©cute les Ã©tapes suivantes :

- Initialise le tokenizer BERT, le modÃ¨le BERT et le modÃ¨le de notation  
- Nettoie et prÃ©traite le texte de l'essai  
- GÃ©nÃ¨re des embeddings BERT pour l'essai  
- Redimensionne les embeddings pour correspondre Ã  la taille d'entrÃ©e attendue  
- Effectue une prÃ©diction avec le modÃ¨le de notation  
- Retourne le score prÃ©dit  

---

## ğŸ§  ConsidÃ©rations de Performance

- **MÃ©moire** : 3008 MB  
- **Timeout** : 180 secondes  
- **Remarque** : Les dÃ©marrages Ã  froid peuvent Ãªtre plus lents  
- **Containers chauds** : Les invocations suivantes sont plus rapides

---

## ğŸ”§ Personnalisation

### Modification de la MÃ©moire et du Timeout  
Dans `lib/DeployFastApiOnAwsLambdaStack.ts` :

```ts
const dockerFunc = new lambda.DockerImageFunction(this, "DockerFunc", {
  memorySize: 4096,  // en MB
  timeout: cdk.Duration.seconds(240),
  // ...
});
```

### Ajout d'une API Gateway

```ts
import * as apigw from 'aws-cdk-lib/aws-apigateway';

const api = new apigw.LambdaRestApi(this, 'ModelApi', {
  handler: dockerFunc,
  proxy: false
});

const modelResource = api.root.addResource('model');
const predictResource = modelResource.addResource('predict');
predictResource.addMethod('POST');
```

---

## ğŸ§¹ Nettoyage

```bash
npx cdk destroy
```

---

## ğŸ’° Optimisation des CoÃ»ts

- Facturation basÃ©e sur la mÃ©moire et le temps d'exÃ©cution  
- Les images des conteneurs Lambda sont stockÃ©es dans **Amazon ECR**  
- Utilisez la **concurrence provisionnÃ©e** pour les charges de travail critiques en termes de performance

---

## ğŸ“š Ressources ComplÃ©mentaires

- [Bonnes Pratiques AWS Lambda](https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html)  
- [Documentation AWS CDK](https://docs.aws.amazon.com/cdk/)  
- [Machine Learning sur AWS Lambda](https://aws.amazon.com/blogs/machine-learning/)  
- [Tutoriel](https://youtu.be/RGIM4JfsSk0/)

---
